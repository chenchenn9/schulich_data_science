{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling \n",
    "\n",
    "Logistic Regression, Naive Bayes, KNN, SVM, Decision Tree. \n",
    "\n",
    "Use the cross validation function to run each model 10 times and calculate an average performance. Remember to use F1 score in the cross validation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Pipline\n",
    "cat_columns = ['Pclass','Sex','Embarked']\n",
    "num_columns = ['Age','SibSp','Parch','Fare']\n",
    "target = 'Survived'\n",
    "\n",
    "cat_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "num_transformer = StandardScaler()\n",
    "preprocessor = ColumnTransformer(transformers = [('cat',cat_transformer, cat_columns),\n",
    "                                                 ('num', num_transformer, num_columns)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "log = LogisticRegression()\n",
    "nb = GaussianNB()\n",
    "knn = KNeighborsClassifier() #default neighbours is 5\n",
    "svc = SVC()\n",
    "dt = DecisionTreeClassifier(random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log Cross-Validation\n",
    "cv_scores_log = cross_val_score(log, x_train, y_train, cv=10, scoring='f1')\n",
    "log.fit(x_train, y_train)\n",
    "y_pred_log = log.predict(x_test)\n",
    "print(\"Cross-validation scores for Logistic Regression: \", cv_scores_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nb Cross-Validation\n",
    "cv_scores_nb = cross_val_score(nb, x_train, y_train, cv=10, scoring='f1')\n",
    "nb.fit(x_train, y_train)\n",
    "y_pred_nb = nb.predict(x_test)\n",
    "print(\"Cross-validation scores for Navie Bayes: \", cv_scores_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN Cross-Validation\n",
    "cv_scores_knn = cross_val_score(knn, x_train, y_train, cv=10, scoring='f1')\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred_knn = knn.predict(x_test)\n",
    "print(\"Cross-validation scores for KNN: \", cv_scores_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC Cross-Validation\n",
    "cv_scores_svc = cross_val_score(svc, x_train, y_train, cv=10, scoring='f1')\n",
    "svc.fit(x_train, y_train)\n",
    "y_pred_svc = svc.predict(x_test)\n",
    "print(\"Cross-validation scores for SVC: \", cv_scores_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dt Cross-Validation\n",
    "cv_scores_dt = cross_val_score(dt, x_train, y_train, cv=10, scoring='f1')\n",
    "dt.fit(x_train, y_train)\n",
    "y_pred_dt = dt.predict(x_test)\n",
    "print(\"Cross-validation scores for Decision Tree: \", cv_scores_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By compare the f1_score choose a best model and start tuneing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decide whether you want to optimize based on Precision or Recall. You will need to explain your choice in relation to the business objective.?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Tuning\n",
    "pred_l_prob = log.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, pred_l_prob[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally we want this curve to be towards the top left; but in a non-ideal world, we want to find the optimal threshold. One way we can do this is by calculating the geometric mean (G-mean) which will find the balance between Sensitivity and Specificity. As a refresher:\n",
    "\n",
    "Sensitivity = True Positive Rate \\\n",
    "Specificity = 1 - False Positive Rate\n",
    "\n",
    "In other words:\n",
    "\n",
    "Sensitivity = TP / (TP + FN) \\\n",
    "Specificity = TN / (FP + TN)\n",
    "\n",
    "To calculate the G-mean, we simply take the square root of the Sensitivity multiplied by the Specificity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmeans = np.sqrt(tpr*(1-fpr))\n",
    "thresholds[np.argmax(gmeans)]\n",
    "#find the index with the highest gmean\n",
    "print(thresholds[np.argmax(gmeans)])\n",
    "print(gmeans[np.argmax(gmeans)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn tuning\n",
    "knn_params = {'n_neighbors':range(50,300)}\n",
    "rs_knn = RandomizedSearchCV(knn, knn_params, n_iter=100, cv=5, scoring='f1')\n",
    "rs_knn.fit(x_train,y_train)\n",
    "rs_knn.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_best = KNeighborsClassifier(n_neighbors=72)\n",
    "knn_best.fit(x_train,y_train)\n",
    "pred_knn_best = knn_best.predict(x_test)\n",
    "print(f1_score(pred_knn_best, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svc tuning\n",
    "svc_params = {'kernel':['linear','poly','rbf']}\n",
    "\n",
    "rs_svc = RandomizedSearchCV(svc, svc_params, n_iter=100, cv=5, scoring='f1')\n",
    "rs_svc.fit(x_train, y_train)\n",
    "rs_svc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gnb tuning\n",
    "yhat_nb = nb.predict_proba(x_test)\n",
    "fpr_nb, tpr_nb, thresholds_nb = roc_curve(y_test, yhat_nb[:,1])\n",
    "gmeans_nb = np.sqrt(tpr_nb*(1-fpr_nb))\n",
    "print(thresholds_nb[np.argmax(gmeans_nb)])\n",
    "print(gmeans_nb[np.argmax(gmeans_nb)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy_score:', accuracy_score(pred,data['cardio']))\n",
    "print('f1_score', f1_score(pred,data['cardio']))\n",
    "print('precision_score:' , precision_score(pred,data['cardio']))\n",
    "print('recall_score:' , recall_score(pred,data['cardio']))\n",
    "print('roc_auc score', roc_auc_score(y_test, pred)) #有没有多种情况"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
