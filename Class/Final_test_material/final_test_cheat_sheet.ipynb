{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n",
    "\n",
    "# Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "\n",
    "## Data Frame check\n",
    "1. using df.info(), look for the following:\n",
    "    missing data (analyze if it need to be fill with 'mean', 'median' or 'other') compare the fillna method. select the one make minium bais\n",
    "    incorrect data type (i.e., a column looks like a number but the data type in df.info() says it's an object) > this means there are data issues (special characters, text where it shouldn't be, etc.)\n",
    "\n",
    "2. using df.describe(), look for the following:\n",
    "    do the ranges make sense?\n",
    "    are there outliers?\n",
    "    which variables are categorical (even if there is a number indicator, like 1,2,3)\n",
    "    which variables are continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "\n",
    "1. check how much of the TOTAL data is missing. If less than 10% of the total data points, then drop the missing data\n",
    "\n",
    "2. if more than 10%:\n",
    "Compare filling methods: Average/Median of the column OR Average/median of the column based on a category. Select the method that doesn't cause drastic differences in results\n",
    "Explain your choice. Make sure that you have checked both methods before finalizing your choice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration\n",
    "\n",
    "1. for continuous variables: plot the boxplots with the x-axis as the output variable, and y-axis as the continuous variable\n",
    "You are looking for difference in spread of data. For example, if output category 0 has a spread of 10-50, but output category 1 has a spread of 25-70, obviously the continuous variable depends differently depending on the output. So this would indicate that this variable is meaningful to the analysis.\n",
    "\n",
    "2. for categorical variables: use groupby() to check proportions\n",
    "Check whether the independent variable categories have different proportions to the dependent variable. For example, when comparing the titanic survival by gender, the first categorical variable is Gender and we're comparing it to a categorical output \"Survived\" - if we see that a higher proportion of Survivors are Women,  vs. the proportion of survivors who were women, then we can conclude gender has something to do with survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original data analysis numerical data\n",
    "#Check the numeric data distrubution and the outliers \n",
    "\n",
    "# List of numerical columns\n",
    "num_cols = ['age', 'height', 'weight', 'ap_hi', 'ap_lo']\n",
    "\n",
    "# Plot histograms for numerical columns\n",
    "for col in num_cols:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.histplot(data[col], bins=30, kde=True)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Plot boxplots of numerical columns against the target variable\n",
    "for col in num_cols:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.boxplot(x='cardio', y=col, data=data)\n",
    "    plt.title(f'{col} vs cardio')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original data analysis categorical data\n",
    "\n",
    "# Select categorical columns\n",
    "categorical_columns = ['gender', 'cholesterol', 'gluc', 'smoke', 'alco', 'active', 'cardio']\n",
    "\n",
    "# Create bar plots for each categorical column\n",
    "fig, axs = plt.subplots(3, 3, figsize=(15, 15))\n",
    "\n",
    "for column, ax in zip(categorical_columns, axs.flatten()):\n",
    "    data[column].value_counts().sort_index().plot(kind='bar', ax=ax, title=column)\n",
    "\n",
    "# Remove unused subplots\n",
    "for ax in axs.flatten()[len(categorical_columns):]:\n",
    "    fig.delaxes(ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of categorical variables\n",
    "cat_cols =['gender','cholesterol','gluc','smoke', 'alco','active']\n",
    "\n",
    "# Plot countplots of categorical columns against the target variable\n",
    "for col in cat_cols:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.countplot(x=col, hue='cardio', data= data)\n",
    "    plt.title(f'{col} vs cardio')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data cleanning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the IQR for 'age'\n",
    "Q1_age = data['age'].quantile(0.25)\n",
    "Q3_age = data['age'].quantile(0.75)\n",
    "IQR_age = Q3_age - Q1_age\n",
    "\n",
    "# Define the boundaries for outliers\n",
    "lower_bound = Q1_age - 1.5 * IQR_age\n",
    "upper_bound = Q3_age + 1.5 * IQR_age\n",
    "\n",
    "# Identify the outliers\n",
    "outliers_age = data[(data['age'] < lower_bound) | (data['age'] > upper_bound)]\n",
    "\n",
    "# Display the outliers\n",
    "outliers_age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the original dataset\n",
    "data_copy = data.copy()\n",
    "\n",
    "# Define the thresholds\n",
    "height_thresholds = [100, 220]\n",
    "weight_thresholds = [40, 140]\n",
    "ap_hi_thresholds = [70, 190]\n",
    "ap_lo_thresholds = [40, 120]\n",
    "bmi_thresholds = [15, 45]\n",
    "\n",
    "# Calculate the number of outliers for each variable\n",
    "height_outliers = data_copy[(data_copy['height'] < height_thresholds[0]) | (data_copy['height'] > height_thresholds[1])].shape[0]\n",
    "weight_outliers = data_copy[(data_copy['weight'] < weight_thresholds[0]) | (data_copy['weight'] > weight_thresholds[1])].shape[0]\n",
    "ap_hi_outliers = data_copy[(data_copy['ap_hi'] < ap_hi_thresholds[0]) | (data_copy['ap_hi'] > ap_hi_thresholds[1])].shape[0]\n",
    "ap_lo_outliers = data_copy[(data_copy['ap_lo'] < ap_lo_thresholds[0]) | (data_copy['ap_lo'] > ap_lo_thresholds[1])].shape[0]\n",
    "bmi_outliers = data_copy[(data_copy['bmi'] < bmi_thresholds[0]) | (data_copy['bmi'] > bmi_thresholds[1])].shape[0]\n",
    "\n",
    "# Print the number of outliers for each variable\n",
    "height_outliers, weight_outliers, ap_hi_outliers, ap_lo_outliers, bmi_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove age outliers\n",
    "data = data[(data['age'] >= lower_bound) & (data['age'] <= upper_bound)]\n",
    "\n",
    "# Remove height outliers\n",
    "data = data[(data['height'] >= 100) & (data['height'] <= 220)]\n",
    "\n",
    "# Remove weight outliers\n",
    "data = data[(data['weight'] >= 40) & (data['weight'] <= 140)]\n",
    "\n",
    "# Remove blood pressure outliers\n",
    "data = data[(data['ap_hi'] >= 80) & (data['ap_hi'] <= 190)]\n",
    "data = data[(data['ap_lo'] >= 50) & (data['ap_lo'] <= 120)]\n",
    "\n",
    "# Remove BMI outliers\n",
    "data = data[(data['bmi'] >= 15) & (data['bmi'] <= 45)]\n",
    "\n",
    "# Show the all rows of  cleaned data\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "corr = data.corr()\n",
    "\n",
    "# Plot heatmap of correlation matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm', cbar=True)\n",
    "plt.title('Correlation matrix of all variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "1. Generate new features from the data you have. This could include:\n",
    "binning (i.e., translate a continuous variable into groups like 5-10, 15-20, etc.)\n",
    "dummy variables (use one hot encoding, or pandas get_dummies() function to convert categorical variables to dummies)\n",
    "define new metrics (e.g., multiply columns together or create custom categories based on multiple variables)\n",
    "\n",
    "2. Check the relationship of engineered features to the output variable, using the methods outlined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BMI to weight measure \n",
    "def over_weight(x):\n",
    "    if x >= 25:\n",
    "        return 1\n",
    "    elif x < 25:\n",
    "        return 0\n",
    "\n",
    "#apply function to data \n",
    "data['over_weight'] = data['bmi'].apply(over_weight)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step ? Build baseline Model\n",
    "\n",
    "Logistic Regression, Naive Bayes, KNN, SVM, Decision Tree. \n",
    "\n",
    "Use the cross validation function to run each model 10 times and calculate an average performance. Remember to use F1 score in the cross validation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Pipline\n",
    "cat_columns = ['Pclass','Sex','Embarked']\n",
    "num_columns = ['Age','SibSp','Parch','Fare']\n",
    "\n",
    "cat_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "num_transformer = StandardScaler()\n",
    "preprocessor = ColumnTransformer(transformers = [('cat',cat_transformer, cat_columns),\n",
    "                                                 ('num', num_transformer, num_columns)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= preprocessor.fit_transform(data[cat_columns + num_columns] )\n",
    "y = data['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2 , random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "log = LogisticRegression()\n",
    "nb = GaussianNB()\n",
    "knn = KNeighborsClassifier() #default neighbours is 5\n",
    "svc = SVC()\n",
    "dt = DecisionTreeClassifier(random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Validation \n",
    "cv_scores_log = cross_val_score(log, x, y, cv=10, scoring='f1').mean()\n",
    "cv_scores_nb = cross_val_score(nb, x, y, cv=10, scoring='f1').mean()\n",
    "cv_scores_knn = cross_val_score(knn, x, y, cv=10, scoring='f1').mean()\n",
    "cv_scores_svc = cross_val_score(svc, x, y, cv=10, scoring='f1').mean()\n",
    "cv_scores_dt = cross_val_score(dt, x, y, cv=10, scoring='f1').mean()\n",
    "\n",
    "#Print out the mean f1 score to chose the best one\n",
    "print(\"Cross-validation scores for Logistic Regression: \", cv_scores_log)\n",
    "print(\"Cross-validation scores for Navie Bayes: \", cv_scores_nb)\n",
    "print(\"Cross-validation scores for KNN: \", cv_scores_knn)\n",
    "print(\"Cross-validation scores for SVC: \", cv_scores_svc)\n",
    "print(\"Cross-validation scores for Decision Tree: \", cv_scores_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By compare the f1_score choose a best model and start tuneing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decide whether you want to optimize based on Precision or Recall. You will need to explain your choice in relation to the business objective.?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Tuning\n",
    "log.fit(x_train,y_train)\n",
    "#find posibility\n",
    "pred_l_prob = log.predict_proba(x_test)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, pred_l_prob[:,1])\n",
    "plt.plot(fpr, tpr)\n",
    "\n",
    "gmeans = np.sqrt(tpr*(1-fpr))\n",
    "thresholds[np.argmax(gmeans)]\n",
    "#find the index with the highest gmean\n",
    "print(thresholds[np.argmax(gmeans)])\n",
    "print(gmeans[np.argmax(gmeans)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change treshhold\n",
    "y_pred_new = []\n",
    "for i in pred_l_prob[:,1]:\n",
    "    if i < 0.36829385617580274:\n",
    "        y_pred_new.append(0)\n",
    "    else:\n",
    "        y_pred_new.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy_score:', accuracy_score(y_pred_new,data['cardio']))\n",
    "print('f1_score', f1_score(y_pred_new,data['cardio']))\n",
    "print('precision_score:' , precision_score(y_pred_new,data['cardio']))\n",
    "print('recall_score:' , recall_score(y_pred_new,data['cardio']))\n",
    "print('roc_auc score', roc_auc_score(y_test, y_pred_new)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn tuning\n",
    "\n",
    "# Select parameters find the best parameters\n",
    "knn_params = {'n_neighbors':range(1,200), 'weight':['uniform','distance'],'metric':['euclidean','manhattan']}\n",
    "#define randomized search\n",
    "rs_knn = RandomizedSearchCV(knn, knn_params, n_iter=100, cv=5, scoring='f1')\n",
    "#fit data in randomized search\n",
    "rs_knn.fit(x_train,y_train)\n",
    "rs_knn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put the new parameters in the \n",
    "knn_best = KNeighborsClassifier(**rs_knn.best_params_)\n",
    "knn_best.fit(x_train,y_train)\n",
    "pred_knn_best = knn_best.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the score\n",
    "y_pred_prob = knn_best.predict_proba(x_test)\n",
    "print('accuracy_score:', accuracy_score(pred_knn_best,data['cardio']))\n",
    "print('f1_score', f1_score(pred_knn_best,data['cardio']))\n",
    "print('precision_score:' , precision_score(pred_knn_best,data['cardio']))\n",
    "print('recall_score:' , recall_score(pred_knn_best,data['cardio']))\n",
    "print('roc_auc score', roc_auc_score(y_test, y_pred_prob)) #有没有多种情况"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC model tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svc tuning\n",
    "svc_params = {     'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'poly', 'rbf','sigmoid'],\n",
    "    'gamma': ['scale', 'auto', 0.1, 1]}\n",
    "rs_svc = RandomizedSearchCV(svc, svc_params, n_iter=100, cv=5, scoring='f1')\n",
    "rs_svc.fit(x_train, y_train)\n",
    "rs_svc.best_params_\n",
    "\n",
    "# change the hyperparameter of svc get best_svc\n",
    "svc_best = SVC(**rs_svc.best_params_)\n",
    "svc_best.fit(x_train, y_train)\n",
    "pre_svc_best = svc_best.predict(x_test)\n",
    "\n",
    "\n",
    "#check the score\n",
    "y_pred_prob = svc_best.predict_proba(x_test)\n",
    "print('accuracy_score:', accuracy_score(pre_svc_best,y_test))\n",
    "print('f1_score', f1_score(pre_svc_best,data['cardio']))\n",
    "print('precision_score:' , precision_score(pre_svc_best,y_test))\n",
    "print('recall_score:' , recall_score(pre_svc_best,y_test))\n",
    "print('roc_auc score', roc_auc_score(y_test, y_pred_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navie Bayes Model and Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gnb tuning\n",
    "#Create parameter list\n",
    "params_nb = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "# Define the models\n",
    "nb = GaussianNB()\n",
    "# Define GridSearchCV\n",
    "rs_nb = RandomizedSearchCV(nb, params_nb, cv=5, scoring='recall')\n",
    "# Fit models\n",
    "rs_nb.fit(x_train, y_train)\n",
    "print(\"Best parameters for KNN: \", rs_nb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_best = GaussianNB(**rs_nb.best_params_)\n",
    "\n",
    "nb_best.fit(x_train, y_train)\n",
    "pre_nb_best = nb_best.predict(x_test)\n",
    "\n",
    "\n",
    "#check the score\n",
    "y_pred_prob = nb_best.predict_proba(x_test)\n",
    "print('accuracy_score:', accuracy_score(pre_nb_best,y_test))\n",
    "print('f1_score', f1_score(pre_nb_best,data['cardio']))\n",
    "print('precision_score:' , precision_score(pre_nb_best,y_test))\n",
    "print('recall_score:' , recall_score(pre_nb_best,y_test))\n",
    "print('roc_auc score', roc_auc_score(y_test, y_pred_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "# select parameters\n",
    "param_dt = {'max_depth': list(range(1, 10)),\n",
    "          'min_samples_leaf': list(range(1, 10)),\n",
    "          'max_features': ['auto', 'sqrt', 'log2']}\n",
    "# Define the models\n",
    "dt = dt(kernel='linear')\n",
    "\n",
    "# Define GridSearchCV /Create the RandomizedSearchCV object\n",
    "gridsearch_dt = GridSearchCV(dt, param_dt, cv=10, scoring='recall') # --> here choose based on the decition made before\n",
    "# If your computer doesn't have much memory\n",
    "randomsearch_dt = RandomizedSearchCV(dt, param_dt, cv=10, n_iter= 15, scoring='f1')\n",
    "\n",
    "# Fit models\n",
    "gridsearch_dt.fit(X_train_transformed, y_train)\n",
    "randomsearch_dt.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "print(\"Best parameters for dt - gridsearch: \", gridsearch_dt.best_params_)\n",
    "print(\"Best parameters for dt - randomsearch: \", randomsearch_dt.best_params_)\n",
    "\n",
    "# Apply the best parameters\n",
    "dt_best = dt(**gridsearch_dt.best_params_)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores_dt = cross_val_score(dt_best, X_train_transformed, y_train, cv=10, scoring='roc_auc')\n",
    "print(\"Cross-validation scores for SVC: \", cv_scores_dt)\n",
    "\n",
    "# Evaluate on the test set\n",
    "pred_dt=dt_best.predict(X_test_transformed)\n",
    "y_pred_prob = dt_best.predict_proba(X_test_transformed)\n",
    "\n",
    "print(f'ROC AUC Score: {roc_auc_score(y_test, y_pred_prob[:,1])}')\n",
    "print(\"optimal threshold F1: \", f1_score(y_test, pred_dt))\n",
    "print(\"optimal threshold precision: \", precision_score(y_test, pred_dt))\n",
    "print(\"optimal threshold recall: \", recall_score(y_test, pred_dt))\n",
    "print(\"optimal threshold accuracy: \", accuracy_score(y_test, pred_dt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
